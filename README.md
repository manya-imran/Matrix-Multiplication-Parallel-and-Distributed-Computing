# Matrix-Multiplication-Parallel-and-Distributed-Computing
The project uses chain multiplication to optimally mutiply the matrices using parallel computing - master and slave machines.
The program reads from a file containing the dimensions of 5 to 7 matrices. The dimensions should be
between 20 and 50. All matricesâ€™ dimensions should be unique i.e. no matrices should have same
dimensions. No square matrices are used

Example input:
20 X 30
30 X 32
32 X 21
21 X 50
50 X 41

Tasks:

a) Find the optimal order of multiplying (considering the most suited loop permutations) the
matrices by calculating the scalar multiplications.

b) After finding the optimal order, multiply the matrices through blocking and non-blocking calls.

c) Then multiply same matrices by Strassens matrix multiplication method through blocking calls.

d) Compare the implementation w.r.t time and processes (2,4,6,8) on 1, 2 and 3 machines (cluster
setup)


Methodology:
- Calculated optimal ordering for multiplying of matrices.
- Multiplied our matrices in sequential order.
- Used dynamic programming to find the optimal order of multiplication on basis of minimum number of multiplication(chain multiplication)
  
Distribution:

- The master sends specific rows of Matrix1 to respective slaves and the slaves multiply it with Matrix B.
- The slave then computes the product and return it to Master. This procedure goes on until all of multiplication is completed.
- Randomly populating the matrices then in Master we are printing those matrices and sending 2 matrices to Slave for multiplication.
- Sending the result back to master and then sending 2 other to the Slave for multiplication and sending the result back to master.
- Sending those two resultant matrices to Slave for multiplication
- Sending the result to the Master then sending the latest resultant and last matrix to Slave for multiplication.
- And finally, sending the last result back to Master and printing it.



